{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "from gensim import corpora, matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一吾輩は猫である', '名前はまだ無い', 'どこで生れたかとんと見当がつかぬ', '何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している', '吾輩はここで始めて人間というものを見た']\n"
     ]
    }
   ],
   "source": [
    "# 青空文庫の「吾輩は猫である」を読み込む\n",
    "with urllib.request.urlopen('https://www.aozora.gr.jp/cards/000148/files/789_ruby_5639.zip') as r:\n",
    "    # zipファイルをバイト型で読み込む\n",
    "    data = r.read()\n",
    "    with zipfile.ZipFile(io.BytesIO(data), 'r') as zipdata:\n",
    "        with zipdata.open(zipdata.namelist()[0], 'r') as f:\n",
    "            text = f.read()\n",
    "            # shift-jisでデコード\n",
    "            text = text.decode('shift_jis')\n",
    "\n",
    "# '-----'で区切られた部分を分割し、本文が始まる部分を取得。non-greedyマッチングは?をつける\n",
    "text = re.split(r'\\-{55}', text)[2]\n",
    "\n",
    "# ルビを削除\n",
    "text = re.sub(r'《.+?》', '', text)\n",
    "\n",
    "# ルビの付く文字列の始まりを示す記号を削除\n",
    "text = re.sub(r'｜', '', text)\n",
    "\n",
    "# 入力者注を削除\n",
    "text = re.sub(r'［＃.+?］', '', text)\n",
    "\n",
    "# アクセント分解された欧文を囲む記号を削除\n",
    "text = re.sub(r'〔.+?〕', '', text)\n",
    "\n",
    "# '底本；'で分割し、最初の部分を取得（必要に応じて）\n",
    "text = text.split('底本；')[0]\n",
    "\n",
    "# 最終的なテキストを単語に分割\n",
    "words = text.split()\n",
    "\n",
    "# 空白文字を削除\n",
    "text = text.replace('\\u3000','')\n",
    "# 改行コードを削除\n",
    "text = text.replace('\\r','').replace('\\n', '')\n",
    "# 「。」を区切り文字として分割\n",
    "sentences = text.split('。')\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []\n",
    "# 各文に形態素解析を行う\n",
    "t = MeCab.Tagger('-Ochasen')\n",
    "# 各文に対して処理、最後は文字列がないため省略\n",
    "for sentence in sentences[:-1]:\n",
    "    sentence_parsed = t.parse(sentence)\n",
    "    word_s = []\n",
    "    # 各文に現れる単語のリストに対して処理を往復\n",
    "    for line in sentence_parsed.splitlines()[:-1]:\n",
    "        word_s.append(line.split('\\t')[2])\n",
    "    words_list.append(word_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['名前', 'は', 'まだ', '無い']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一吾輩は猫である</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>名前はまだ無い</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>どこで生れたかとんと見当がつかぬ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>吾輩はここで始めて人間というものを見た</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence  scores\n",
       "0                             一吾輩は猫である       0\n",
       "1                              名前はまだ無い       0\n",
       "2                     どこで生れたかとんと見当がつかぬ       0\n",
       "3  何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している      -1\n",
       "4                  吾輩はここで始めて人間というものを見た       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 日本語極性辞書を読み込む\n",
    "with urllib.request.urlopen('https://www.cl.ecei.tohoku.ac.jp/resources/sent_lex/wago.121808.pn') as f:\n",
    "    text_wago = f.read().decode('utf-8')\n",
    "\n",
    "# dfとして読み込む\n",
    "df = pd.read_csv(io.StringIO(text_wago), header=None, sep='\\t')\n",
    "\n",
    "# 単語とスコアを対応させる辞書を作成\n",
    "word2score = {}\n",
    "values = {\n",
    "    'ポジ（経験）':1,\n",
    "    'ポジ（評価）':1,\n",
    "    'ネガ（経験）':-1,\n",
    "    'ネガ（評価）':-1\n",
    "}\n",
    "\n",
    "for word, label in zip(df.loc[:,1], df.loc[:,0]):\n",
    "    word2score[word] = values[label]\n",
    "\n",
    "scores = []\n",
    "# 各文書のスコアを算出\n",
    "for words in words_list:\n",
    "    score = 0\n",
    "    # 単語が辞書に現れていればそのスコアを加算\n",
    "    for word in words:\n",
    "        if word in word2score:\n",
    "            score += word2score[word]\n",
    "    scores.append(score)\n",
    "\n",
    "scores_df = pd.DataFrame({'sentence': sentences[:-1],\n",
    "                          'scores': scores}, columns=['sentence', 'scores'])\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>「あのね</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence score\n",
       "count      7489     0\n",
       "unique     7486     0\n",
       "top        「あのね   NaN\n",
       "freq          2   NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
